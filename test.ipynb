{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "560860fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da6055ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d21f9-0c7d-4d5e-83f8-babbd0114c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.jpg\n",
    "# apple.jpg\n",
    "def test_orb(src:os.PathLike, nfeatures:int, debug=False):\n",
    "    \n",
    "    img = cv2.imread(src)\n",
    "            \n",
    "    # blur된 이미지를 gray로 변환 (바로 gray로 변환하지 않음)\n",
    "    blurred = cv2.GaussianBlur(img, (5, 5), 0)  \n",
    "    gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)     \n",
    "    \n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    orb = cv2.ORB()\n",
    "    orb = orb.create(\n",
    "        nfeatures=nfeatures, # 상위 몇개의 특징점을 사용할 것인지\n",
    "        scaleFactor=1.2, \n",
    "        nlevels=8,\n",
    "        edgeThreshold=15, # edgeThreshold와 patchSize는 서로 비례해야 함. edgeThreshold는 제외할 이미지 경계에 사용되는 값\n",
    "        # Backgroud image는 이 값을 줄여야 함.\n",
    "        firstLevel=0,\n",
    "        WTA_K=2, # BRIEF descriptor가 사용할 bit 가짓수. binary이므로 1bit임.\n",
    "        scoreType=cv2.ORB_HARRIS_SCORE, \n",
    "        patchSize=31, # edgeThreshold와 크거나 같은 값으로 설정해야 함.\n",
    "        fastThreshold=10, # FAST detector에서 근처 픽셀들이 얼마나 밝거나 어두워야 하는지에 대한 임계값\n",
    "    )\n",
    "\n",
    "    kp1, _ = orb.detectAndCompute(gray, None)\n",
    "    \n",
    "    def non_max_suppression(keypoints, min_distance=5):\n",
    "        keypoints = sorted(keypoints, key=lambda x: x.response, reverse=True)\n",
    "        selected = []\n",
    "        for kp in keypoints:            \n",
    "            if any(distance(kp, s) < min_distance for s in selected):\n",
    "                continue\n",
    "            selected.append(kp)\n",
    "        return selected\n",
    "\n",
    "    def distance(kp1, kp2):\n",
    "        return np.sqrt((kp1.pt[0] - kp2.pt[0])**2 + (kp1.pt[1] - kp2.pt[1])**2)\n",
    "    \n",
    "    kp1 = non_max_suppression(kp1)\n",
    "    if debug:\n",
    "        result = img.copy()\n",
    "        for kp in kp1:\n",
    "            x, y = kp.pt\n",
    "            cv2.circle(result, (int(x), int(y)), 1, (255, 0, 0), -1)\n",
    "            \n",
    "        plt.imshow(result)\n",
    "        plt.title('object image orb')\n",
    "        plt.show()\n",
    "    print(f\"total keypoints: {len(kp1)}\")\n",
    "    \n",
    "    return img, kp1\n",
    "    \n",
    "                 \n",
    "test_orb(src=\"apple.jpg\", nfeatures=300, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_harris(threshold=0.01):\n",
    "    \"\"\"\n",
    "    Threshold should be tuned.\n",
    "    \"\"\"\n",
    "    src = cv2.imread(\"apple.jpg\")\n",
    "    gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    dst = cv2.cornerHarris(\n",
    "        gray,\n",
    "        blockSize=2, # 이웃 픽셀의 크기\n",
    "        ksize=3, # Sobel 미분 커널의 크기\n",
    "        k=0.04 # 해리스 코너 검출 상수    \n",
    "    )\n",
    "    # dst = cv2.dilate(dst, None) # 팽창 연산을 통해 코너 검출 결과를 표시하기 좋게 만듦.\n",
    "    \n",
    "    # threshold = 0.01\n",
    "    src[dst > threshold * dst.max()] = [255, 0, 0]  # dst.max()에서 1% 이상의 값만 파란색으로 표시.\n",
    "    \n",
    "    plt.imshow(src)\n",
    "    plt.title('my picture')\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "test_harris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb11735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_canny():\n",
    "    src = cv2.imread(\"apple.jpg\")    \n",
    "    canny = cv2.Canny(src, 60, 200)    \n",
    "    contours, _ = cv2.findContours(canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    contour_image =  cv2.drawContours(src, contours, -1, (255, 0, 0), 1)\n",
    "    plt.imshow(contour_image)\n",
    "    plt.title('my picture')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "test_canny()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd51eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 큰 윤곽선 읽기.\n",
    "def test_contour():\n",
    "    # 이미지 읽기\n",
    "    image = cv2.imread('apple.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # 윤곽선 추출\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    # 외곽 윤곽선만 찾기\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # 결과 이미지 생성\n",
    "    result = np.zeros_like(image)\n",
    "\n",
    "    # 가장 큰 윤곽선 찾기 (일반적으로 이것이 외곽 윤곽선)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # 윤곽선 단순화\n",
    "    epsilon = 0.02 * cv2.arcLength(largest_contour, True)\n",
    "    approx = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "\n",
    "    # 단순화된 윤곽선의 점들을 일정 간격으로 추출\n",
    "    for i in range(0, len(approx), 1):  # 5는 간격을 조절하는 파라미터\n",
    "        cv2.circle(result, tuple(approx[i][0]), 2, (0, 255, 0), -1)\n",
    "    \n",
    "    plt.imshow(result)\n",
    "    plt.title('my picture')\n",
    "    plt.show()\n",
    "\n",
    "test_contour()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c271acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "# forest.jpg\n",
    "# apple.jpg\n",
    "\n",
    "def non_max_suppression(keypoints, min_distance=5):\n",
    "        keypoints = sorted(keypoints, key=lambda x: x.response, reverse=True)        \n",
    "        selected = []\n",
    "        for kp in keypoints:            \n",
    "            if any(distance(kp, s) < min_distance for s in selected):\n",
    "                continue                        \n",
    "            selected.append(kp)        \n",
    "                \n",
    "        return selected\n",
    "\n",
    "def distance(kp1, kp2):\n",
    "    return np.sqrt((kp1.pt[0] - kp2.pt[0])**2 + (kp1.pt[1] - kp2.pt[1])**2)\n",
    "\n",
    "def object_orb(src:os.PathLike, nfeatures:int, debug=False):\n",
    "    \"\"\"\n",
    "    removebg 처리하니 edgeThreshold 높아도 좋음.\n",
    "    얇은 구조에 대해서 너무 많은 특징점이 검출되는 것을 방지하기 위해(clustering) non-maximum suppression을 사용함.\n",
    "    nfeature에 따라 너무 적은 특징점이 나오는 경우 존재.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(src)\n",
    "            \n",
    "    # blur된 이미지를 gray로 변환 (바로 gray로 변환하지 않음)\n",
    "    blurred = cv2.GaussianBlur(img, (5, 5), 0)  \n",
    "    gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)     \n",
    "    \n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    orb = cv2.ORB()\n",
    "    orb = orb.create(\n",
    "        nfeatures=nfeatures, # 상위 몇개의 특징점을 사용할 것인지\n",
    "        scaleFactor=1.2, \n",
    "        nlevels=8,\n",
    "        edgeThreshold=15, # edgeThreshold와 patchSize는 서로 비례해야 함. edgeThreshold는 제외할 이미지 경계에 사용되는 값\n",
    "        # Backgroud image는 이 값을 줄여야 함.\n",
    "        firstLevel=0,\n",
    "        WTA_K=2, # BRIEF descriptor가 사용할 bit 가짓수. binary이므로 1bit임.\n",
    "        scoreType=cv2.ORB_HARRIS_SCORE, \n",
    "        patchSize=31, # edgeThreshold와 크거나 같은 값으로 설정해야 함.\n",
    "        fastThreshold=10, # FAST detector에서 근처 픽셀들이 얼마나 밝거나 어두워야 하는지에 대한 임계값\n",
    "    )\n",
    "\n",
    "    kp1, _ = orb.detectAndCompute(gray, None)        \n",
    "    \n",
    "    kp1 = non_max_suppression(kp1)\n",
    "    if debug:\n",
    "        result = img.copy()\n",
    "        for kp in kp1:\n",
    "            x, y = kp.pt\n",
    "            cv2.circle(result, (int(x), int(y)), 1, (255, 0, 0), -1)\n",
    "            \n",
    "        plt.imshow(result)\n",
    "        plt.title('object image orb')\n",
    "        plt.show()\n",
    "    print(f\"total keypoints: {len(kp1)}\")\n",
    "    \n",
    "    return img, kp1\n",
    "    \n",
    "\n",
    "def background_orb(src:os.PathLike, nfeatures:int, debug=False):\n",
    "    \"\"\"\n",
    "    많은 특징점이 필요함.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(src)\n",
    "            \n",
    "    # blur된 이미지를 gray로 변환 (바로 gray로 변환하지 않음)\n",
    "    blurred = cv2.GaussianBlur(img, (5, 5), 0)  \n",
    "    gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)     \n",
    "    \n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    orb = cv2.ORB()\n",
    "    orb = orb.create(\n",
    "        nfeatures=nfeatures, # 상위 몇개의 특징점을 사용할 것인지\n",
    "        scaleFactor=1.2, \n",
    "        nlevels=8,\n",
    "        edgeThreshold=15, # edgeThreshold와 patchSize는 서로 비례해야 함. edgeThreshold는 제외할 이미지 경계에 사용되는 값\n",
    "        # Backgroud image는 이 값을 줄여야 함.\n",
    "        firstLevel=0,\n",
    "        WTA_K=2, # BRIEF descriptor가 사용할 bit 가짓수. binary이므로 1bit임.\n",
    "        scoreType=cv2.ORB_HARRIS_SCORE, \n",
    "        patchSize=15, # edgeThreshold와 크거나 같은 값으로 설정해야 함.\n",
    "        fastThreshold=10, # FAST detector에서 근처 픽셀들이 얼마나 밝거나 어두워야 하는지에 대한 임계값\n",
    "    )\n",
    "\n",
    "    kp1, _ = orb.detectAndCompute(gray, None)        \n",
    "    \n",
    "    kp1 = non_max_suppression(kp1, min_distance=3)\n",
    "    if debug:\n",
    "        result = img.copy()\n",
    "        for kp in kp1:\n",
    "            x, y = kp.pt\n",
    "            cv2.circle(result, (int(x), int(y)), 1, (255, 0, 0), -1)\n",
    "            \n",
    "        plt.imshow(result)\n",
    "        plt.title('object image orb')\n",
    "        plt.show()\n",
    "    print(f\"back keypoints: {len(kp1)}\")\n",
    "    \n",
    "    return img, kp1\n",
    "    \n",
    "                 \n",
    "obj_img, obj_kp = object_orb(src=\"apple.jpg\", nfeatures=200, debug=True)\n",
    "back_img, back_kp = background_orb(src=\"forest.jpg\", nfeatures=1000, debug=True)\n",
    "\n",
    "# 현재 PCA 하기 전에 scaling하지 않았음.\n",
    "pca = PCA(n_components=2)\n",
    "pca_obj_kp = pca.fit_transform(np.array([kp.pt for kp in obj_kp]))\n",
    "\n",
    "\n",
    "def calculate_max_distance(pca_points):\n",
    "    # 각 점에서 다른 모든 점까지의 벡터 계산\n",
    "    diff = pca_points[:, np.newaxis, :] - pca_points[np.newaxis, :, :]    \n",
    "    \n",
    "    # 거리의 제곱 계산\n",
    "    squared_distances = np.sum(diff**2, axis=-1)    \n",
    "    \n",
    "    # 대각선(자기 자신과의 거리)을 제외하고 최대값 찾기\n",
    "    max_squared_distance = np.max(squared_distances[~np.eye(squared_distances.shape[0], dtype=bool)])\n",
    "    \n",
    "    # 제곱근을 취해 실제 거리 계산\n",
    "    max_distance = np.sqrt(max_squared_distance)\n",
    "    \n",
    "    return max_distance\n",
    "\n",
    "max_distance = calculate_max_distance(pca_obj_kp)\n",
    "print(f\"max distance: {max_distance}\")\n",
    "\n",
    "def map_keypoints_to_bounding_circle(radius, kp_coords, num_radius_divisions=4, num_angle_divisions=8):\n",
    "    \"\"\"\n",
    "    center_x, center_y: 이미지의 중심점(PCA로 변환된 좌표여서 0, 0)\n",
    "    \n",
    "    radius: 원의 반지름 (최대 거리 / 2 + 2)\n",
    "    \"\"\"\n",
    "    # 이미지의 중심점 계산 (PCA로 변환된 좌표여서 0, 0)\n",
    "    center_x, center_y = 0, 0                    \n",
    "    \n",
    "    # 중심점으로부터의 상대 좌표 계산\n",
    "    # relative_coords = kp_coords - [center_x, center_y]\n",
    "    \n",
    "    # 거리 계산\n",
    "    distances = np.sqrt(np.sum(kp_coords**2, axis=1))        \n",
    "    # 각도 계산 (라디안)\n",
    "    angles = np.arctan2(kp_coords[:, 1], kp_coords[:, 0])    \n",
    "    # 각도를 0-360도로 변환\n",
    "    angles = np.degrees(angles) % 360\n",
    "    \n",
    "    # 반지름 인덱스 계산\n",
    "    radius_indices = np.minimum((distances / (radius / num_radius_divisions)).astype(int), num_radius_divisions - 1)\n",
    "    \n",
    "    # 각도 인덱스 계산\n",
    "    angle_indices = (angles / (360 / num_angle_divisions)).astype(int)\n",
    "    \n",
    "    # 결과 생성\n",
    "    mapped_keypoints = list(zip(radius_indices, angle_indices, kp_coords))\n",
    "    \n",
    "    return mapped_keypoints\n",
    "\n",
    "mapped_obj_kp = map_keypoints_to_bounding_circle(max_distance / 2, pca_obj_kp)\n",
    "\n",
    "back_kp_coords = np.array([kp.pt for kp in back_kp])\n",
    "N = len(obj_kp)\n",
    "M = len(back_kp)\n",
    "\n",
    "\n",
    "def background_pca_coords_with_nn(back_kp_coords, n_neighbors):\n",
    "    neighbors = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ball_tree').fit(back_kp_coords)    \n",
    "    pca_class_list = [PCA(n_components=2)] * len(back_kp_coords)\n",
    "    _, indices = neighbors.kneighbors(back_kp_coords) # shape: M x N\n",
    "        \n",
    "    pca_back_kps = np.array([pca_class_list[i].fit_transform(back_kp_coords[idx, :]) \n",
    "                             for i, idx in enumerate(indices)])\n",
    "        \n",
    "    return pca_back_kps, pca_class_list\n",
    "\n",
    "pca_back_kps, pca_class_list = background_pca_coords_with_nn(back_kp_coords, N)\n",
    "\n",
    "back_max_distances = [calculate_max_distance(pca_back_kps[i]) for i in range(M)]\n",
    "mapped_back_kps = [map_keypoints_to_bounding_circle(back_max_distances[i] / 2, pca_back_kps[i]) for i in range(M)]\n",
    "\n",
    "\n",
    "# print(pca_back_kps.shape)\n",
    "# plt.scatter(*pca_back_kps[0].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e54957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] DEBUG MODE: YOU ARE IN DEBUG MODE. PLEASE debug=False IN PRODUCTION.\n",
      "object keypoints: 85\n",
      "Background keypoints: 382\n",
      "object keypoints: 85, background keypoints: 382, T: 8\n",
      "ObjectImg - apple.jpg  / set_pca  elapsed time: 0.0022153854370117188\n",
      "Background PCAs shape: (382, 85, 2)\n",
      "BackgroundImg - forest.jpg  / set_pca  elapsed time: 0.1145467758178711\n",
      "Object bounding circle radius: 170.71478872113482\n",
      "super()._num_radius_divisions, super()._num_angle_divisions: 4, 8\n",
      "ObjectImg - apple.jpg  / set_histogram  elapsed time: 0.0003631114959716797\n",
      "BackgroundImg - forest.jpg  / set_histograms  elapsed time: 0.002679109573364258\n",
      "elapsed time in compute_refined_scores: 0.09723448753356934\n",
      "0.3778790302830938 0.9297219796196592\n"
     ]
    }
   ],
   "source": [
    "# 한 번 추적해가며 디버깅 해보기\n",
    "from img_class.background_img import BackgroundImg\n",
    "from img_class.object_img import ObjectImg\n",
    "from utils.shape_match_utils import compute_refined_score\n",
    "import time\n",
    "\n",
    "DEBUG = True\n",
    "obj_img = ObjectImg(\"apple.jpg\")\n",
    "back_img = BackgroundImg(\"forest.jpg\")\n",
    "if DEBUG:\n",
    "    print(\"[WARNING] DEBUG MODE: YOU ARE IN DEBUG MODE. PLEASE debug=False IN PRODUCTION.\")\n",
    "\n",
    "# debug settings.\n",
    "obj_img.set_method_debug(\"set_orb\", debug=False)\n",
    "obj_img.set_method_debug(\"set_pca\", debug=DEBUG)\n",
    "obj_img.set_method_debug(\"set_histogram\", debug=DEBUG)\n",
    "back_img.set_method_debug(\"set_orb\", debug=False)\n",
    "back_img.set_method_debug(\"set_pca\", debug=DEBUG)\n",
    "back_img.set_method_debug(\"set_histograms\", debug=DEBUG)\n",
    "\n",
    "obj_img.set_orb(nfeatures=300, nms_distance=5)\n",
    "back_img.set_orb(nfeatures=1000, nms_distance=3)\n",
    "\n",
    "N = obj_img.get_kp_length()\n",
    "M = back_img.get_kp_length()\n",
    "T = 8\n",
    "if DEBUG:\n",
    "    print(f\"object keypoints: {N}, background keypoints: {M}, T: {T}\")\n",
    "\n",
    "obj_img.set_pca()\n",
    "back_img.set_pca(N, T)\n",
    "\n",
    "obj_img.set_histogram()\n",
    "back_img.set_histograms()\n",
    "if DEBUG:\n",
    "    t1 = time.time()\n",
    "scores = [compute_refined_score(back_img, obj_img, m, scale_weight=0.3) for m in range(M)]\n",
    "if DEBUG:\n",
    "    t2 = time.time()\n",
    "    print(f\"elapsed time in compute_refined_scores: {t2 - t1}\")\n",
    "\n",
    "print(min(scores), max(scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sw-capstone-3-10-0-uo1yqq9--py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
